Starting pipeline donors_choose (c457ce34-6ad0-4c71-a24a-6a2bdf26bc52) at 2019-05-30 11:27:57.878206
Input data: /Users/satej/Documents/workspace/classwork/machine-learning/capp30254/hw5/code/input/projects_2012_2013.csv (SHA-256: b34fdb1924369afb5df5a1ba886f7269b7455b9baf2fd2248bc3409fcfa8f18f)
Pipeline library version: 4e3cdb7

Pipeline settings:
    summarize: True
    data_preprocessors: None
    feature_generators: [categorize-school_city, categorize-school_state, categorize-primary_focus_subject, categorize-primary_focus_area, categorize-resource_type, categorize-poverty_level, categorize-grade_level, binarize-school_charter, binarize-school_magnet, replace-missing-values-with-value(students_reached,0), scale-by-max(students_reached_clean), scale-by-max(total_price_including_optional_support), binarize-eligible_double_your_impact_match]
    models: {'LogisticRegression-C0.01-penaltyl1': LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l1', random_state=None, solver='warn',
          tol=0.0001, verbose=0, warm_start=False), 'LogisticRegression-C0.01-penaltyl2': LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=None, solver='warn',
          tol=0.0001, verbose=0, warm_start=False), 'LogisticRegression-C0.1-penaltyl1': LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l1', random_state=None, solver='warn',
          tol=0.0001, verbose=0, warm_start=False), 'LogisticRegression-C0.1-penaltyl2': LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=None, solver='warn',
          tol=0.0001, verbose=0, warm_start=False), 'LogisticRegression-C1-penaltyl1': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l1', random_state=None, solver='warn',
          tol=0.0001, verbose=0, warm_start=False), 'LogisticRegression-C1-penaltyl2': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=None, solver='warn',
          tol=0.0001, verbose=0, warm_start=False), 'LogisticRegression-C10-penaltyl1': LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l1', random_state=None, solver='warn',
          tol=0.0001, verbose=0, warm_start=False), 'LogisticRegression-C10-penaltyl2': LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=None, solver='warn',
          tol=0.0001, verbose=0, warm_start=False), 'LogisticRegression-C100-penaltyl1': LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l1', random_state=None, solver='warn',
          tol=0.0001, verbose=0, warm_start=False), 'LogisticRegression-C100-penaltyl2': LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=None, solver='warn',
          tol=0.0001, verbose=0, warm_start=False), 'KNeighborsClassifier-n_neighbors10': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=None, n_neighbors=10, p=2,
           weights='uniform'), 'KNeighborsClassifier-n_neighbors50': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=None, n_neighbors=50, p=2,
           weights='uniform'), 'KNeighborsClassifier-n_neighbors100': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=None, n_neighbors=100, p=2,
           weights='uniform'), 'DecisionTreeClassifier-max_depthNone': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best'), 'DecisionTreeClassifier-max_depth1': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best'), 'DecisionTreeClassifier-max_depth5': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best'), 'DecisionTreeClassifier-max_depth10': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best'), 'DecisionTreeClassifier-max_depth50': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=50,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best'), 'DecisionTreeClassifier-max_depth100': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=100,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best'), 'GradientBoostingClassifier-learning_rate0.1': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=None,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False), 'GradientBoostingClassifier-learning_rate0.5': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.5, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=None,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False), 'GradientBoostingClassifier-learning_rate2.0': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=2.0, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=None,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False), 'BaggingClassifier-max_samples0.1': BaggingClassifier(base_estimator=None, bootstrap=True,
         bootstrap_features=False, max_features=1.0, max_samples=0.1,
         n_estimators=10, n_jobs=None, oob_score=False, random_state=None,
         verbose=0, warm_start=False), 'BaggingClassifier-max_samples0.5': BaggingClassifier(base_estimator=None, bootstrap=True,
         bootstrap_features=False, max_features=1.0, max_samples=0.5,
         n_estimators=10, n_jobs=None, oob_score=False, random_state=None,
         verbose=0, warm_start=False), 'BaggingClassifier-max_samples1.0': BaggingClassifier(base_estimator=None, bootstrap=True,
         bootstrap_features=False, max_features=1.0, max_samples=1.0,
         n_estimators=10, n_jobs=None, oob_score=False, random_state=None,
         verbose=0, warm_start=False), 'RandomForestClassifier': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)}
    name: donors_choose
    output_root_dir: /Users/satej/Documents/workspace/classwork/machine-learning/capp30254/hw5/code/output

Loading data
Running custom summary function

Running transformations for cleaning
    Applying transformation (1/4): convert-date_posted-to-datetime 
    date_posted -> date_posted
    Applying transformation (2/4): convert-datefullyfunded-to-datetime 
    datefullyfunded -> datefullyfunded
    Applying transformation (3/4): month_posted 
    ['date_posted'] -> month_posted
    Applying transformation (4/4): funded_in_60_days 
    ['date_posted', 'datefullyfunded'] -> funded_in_60_days


Running transformations for feature generation
    Applying transformation (1/13): categorize-school_city 
    ['school_city'] -> school_city_categorical
    Applying transformation (2/13): categorize-school_state 
    ['school_state'] -> school_state_categorical
    Applying transformation (3/13): categorize-primary_focus_subject 
    ['primary_focus_subject'] -> primary_focus_subject_categorical
    Applying transformation (4/13): categorize-primary_focus_area 
    ['primary_focus_area'] -> primary_focus_area_categorical
    Applying transformation (5/13): categorize-resource_type 
    ['resource_type'] -> resource_type_categorical
    Applying transformation (6/13): categorize-poverty_level 
    ['poverty_level'] -> poverty_level_categorical
    Applying transformation (7/13): categorize-grade_level 
    ['grade_level'] -> grade_level_categorical
    Applying transformation (8/13): binarize-school_charter 
    ['school_charter'] -> school_charter_binary
    Applying transformation (9/13): binarize-school_magnet 
    ['school_magnet'] -> school_magnet_binary
    Applying transformation (10/13): replace-missing-values-with-value(students_reached,0) 
    ['students_reached'] -> students_reached_clean
    Applying transformation (11/13): scale-by-max(students_reached_clean) 
    ['students_reached_clean'] -> students_reached_clean_scaled
    Applying transformation (12/13): scale-by-max(total_price_including_optional_support) 
    ['total_price_including_optional_support'] -> total_price_including_optional_support_scaled
    Applying transformation (13/13): binarize-eligible_double_your_impact_match 
    ['eligible_double_your_impact_match'] -> eligible_double_your_impact_match_binary

Training models.
Features: ['total_price_including_optional_support_scaled', 'school_state_categorical', 'resource_type_categorical', 'eligible_double_your_impact_match_binary', 'school_magnet_binary', 'primary_focus_area_categorical', 'grade_level_categorical', 'school_city_categorical', 'students_reached_clean_scaled', 'poverty_level_categorical', 'primary_focus_subject_categorical', 'school_charter_binary', 'students_reached_clean']
Fitting: funded_in_60_days
    Training model LogisticRegression-C0.01-penaltyl1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LogisticRegression-C0.01-penaltyl2
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LogisticRegression-C0.1-penaltyl1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LogisticRegression-C0.1-penaltyl2
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LogisticRegression-C1-penaltyl1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LogisticRegression-C1-penaltyl2
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LogisticRegression-C10-penaltyl1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LogisticRegression-C10-penaltyl2
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LogisticRegression-C100-penaltyl1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LogisticRegression-C100-penaltyl2
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model KNeighborsClassifier-n_neighbors10
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model KNeighborsClassifier-n_neighbors50
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model KNeighborsClassifier-n_neighbors100
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model DecisionTreeClassifier-max_depthNone
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model DecisionTreeClassifier-max_depth1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model DecisionTreeClassifier-max_depth5
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model DecisionTreeClassifier-max_depth10
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model DecisionTreeClassifier-max_depth50
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model DecisionTreeClassifier-max_depth100
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model GradientBoostingClassifier-learning_rate0.1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model GradientBoostingClassifier-learning_rate0.5
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model GradientBoostingClassifier-learning_rate2.0
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model BaggingClassifier-max_samples0.1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model BaggingClassifier-max_samples0.5
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model BaggingClassifier-max_samples1.0
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model RandomForestClassifier
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
Testing models.
    Evaluating model LogisticRegression-C0.01-penaltyl1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LogisticRegression-C0.01-penaltyl2
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LogisticRegression-C0.1-penaltyl1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LogisticRegression-C0.1-penaltyl2
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LogisticRegression-C1-penaltyl1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LogisticRegression-C1-penaltyl2
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LogisticRegression-C10-penaltyl1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LogisticRegression-C10-penaltyl2
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LogisticRegression-C100-penaltyl1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LogisticRegression-C100-penaltyl2
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model KNeighborsClassifier-n_neighbors10
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model KNeighborsClassifier-n_neighbors50
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model KNeighborsClassifier-n_neighbors100
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model DecisionTreeClassifier-max_depthNone
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model DecisionTreeClassifier-max_depth1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model DecisionTreeClassifier-max_depth5
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model DecisionTreeClassifier-max_depth10
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model DecisionTreeClassifier-max_depth50
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model DecisionTreeClassifier-max_depth100
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model GradientBoostingClassifier-learning_rate0.1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model GradientBoostingClassifier-learning_rate0.5
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model GradientBoostingClassifier-learning_rate2.0
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model BaggingClassifier-max_samples0.1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model BaggingClassifier-max_samples0.5
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model BaggingClassifier-max_samples1.0
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model RandomForestClassifier
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
Copying artifacts to stable path
