Starting pipeline donors_choose (7257ef94-4a67-4fb0-998b-d3bb2535ee66) at 2019-05-30 15:56:09.435115
Input data: /Users/satej/Documents/workspace/classwork/machine-learning/capp30254/hw5/code/input/projects_2012_2013.csv (SHA-256: b34fdb1924369afb5df5a1ba886f7269b7455b9baf2fd2248bc3409fcfa8f18f)
Pipeline library version: 7d8a21f

Pipeline settings:
    summarize: True
    data_preprocessors: [replace-missing-values-with-value(students_reached,0)]
    feature_generators: [categorize-school_city, categorize-school_state, categorize-primary_focus_subject, categorize-primary_focus_area, categorize-resource_type, categorize-poverty_level, categorize-grade_level, binarize-school_charter, binarize-school_magnet, scale-by-max(students_reached_clean), scale-by-max(total_price_including_optional_support), binarize-eligible_double_your_impact_match]
    models: {'LinearSVC-C0.01-penaltyl2': LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
     verbose=0), 'LinearSVC-C0.1-penaltyl2': LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
     verbose=0), 'LinearSVC-C1-penaltyl2': LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
     verbose=0), 'LinearSVC-C10-penaltyl2': LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
     verbose=0), 'LinearSVC-C100-penaltyl2': LinearSVC(C=100, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
     verbose=0), 'LogisticRegression-C0.01-penaltyl1-n_jobs-1': LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,
          penalty='l1', random_state=None, solver='warn', tol=0.0001,
          verbose=0, warm_start=False), 'LogisticRegression-C0.01-penaltyl2-n_jobs-1': LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,
          penalty='l2', random_state=None, solver='warn', tol=0.0001,
          verbose=0, warm_start=False), 'LogisticRegression-C0.1-penaltyl1-n_jobs-1': LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,
          penalty='l1', random_state=None, solver='warn', tol=0.0001,
          verbose=0, warm_start=False), 'LogisticRegression-C0.1-penaltyl2-n_jobs-1': LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,
          penalty='l2', random_state=None, solver='warn', tol=0.0001,
          verbose=0, warm_start=False), 'LogisticRegression-C1-penaltyl1-n_jobs-1': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,
          penalty='l1', random_state=None, solver='warn', tol=0.0001,
          verbose=0, warm_start=False), 'LogisticRegression-C1-penaltyl2-n_jobs-1': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,
          penalty='l2', random_state=None, solver='warn', tol=0.0001,
          verbose=0, warm_start=False), 'LogisticRegression-C10-penaltyl1-n_jobs-1': LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,
          penalty='l1', random_state=None, solver='warn', tol=0.0001,
          verbose=0, warm_start=False), 'LogisticRegression-C10-penaltyl2-n_jobs-1': LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,
          penalty='l2', random_state=None, solver='warn', tol=0.0001,
          verbose=0, warm_start=False), 'LogisticRegression-C100-penaltyl1-n_jobs-1': LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,
          penalty='l1', random_state=None, solver='warn', tol=0.0001,
          verbose=0, warm_start=False), 'LogisticRegression-C100-penaltyl2-n_jobs-1': LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,
          penalty='l2', random_state=None, solver='warn', tol=0.0001,
          verbose=0, warm_start=False), 'KNeighborsClassifier-n_neighbors10-n_jobs-1': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=-1, n_neighbors=10, p=2,
           weights='uniform'), 'KNeighborsClassifier-n_neighbors50-n_jobs-1': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=-1, n_neighbors=50, p=2,
           weights='uniform'), 'KNeighborsClassifier-n_neighbors100-n_jobs-1': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=-1, n_neighbors=100, p=2,
           weights='uniform'), 'DecisionTreeClassifier-max_depthNone': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best'), 'DecisionTreeClassifier-max_depth1': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best'), 'DecisionTreeClassifier-max_depth5': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best'), 'DecisionTreeClassifier-max_depth10': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best'), 'DecisionTreeClassifier-max_depth50': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=50,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best'), 'DecisionTreeClassifier-max_depth100': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=100,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best'), 'GradientBoostingClassifier-learning_rate0.1': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=None,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False), 'GradientBoostingClassifier-learning_rate0.5': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.5, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=None,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False), 'GradientBoostingClassifier-learning_rate2.0': GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=2.0, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=None,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False), 'BaggingClassifier-max_samples0.1-n_jobs-1': BaggingClassifier(base_estimator=None, bootstrap=True,
         bootstrap_features=False, max_features=1.0, max_samples=0.1,
         n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,
         verbose=0, warm_start=False), 'BaggingClassifier-max_samples0.5-n_jobs-1': BaggingClassifier(base_estimator=None, bootstrap=True,
         bootstrap_features=False, max_features=1.0, max_samples=0.5,
         n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,
         verbose=0, warm_start=False), 'BaggingClassifier-max_samples1.0-n_jobs-1': BaggingClassifier(base_estimator=None, bootstrap=True,
         bootstrap_features=False, max_features=1.0, max_samples=1.0,
         n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,
         verbose=0, warm_start=False), 'RandomForestClassifier-n_estimators10-max_depthNone-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'RandomForestClassifier-n_estimators10-max_depth1-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=1, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'RandomForestClassifier-n_estimators10-max_depth5-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=5, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'RandomForestClassifier-n_estimators10-max_depth10-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=10, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'RandomForestClassifier-n_estimators10-max_depth50-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=50, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'RandomForestClassifier-n_estimators10-max_depth100-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=100, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'RandomForestClassifier-n_estimators100-max_depthNone-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'RandomForestClassifier-n_estimators100-max_depth1-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=1, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'RandomForestClassifier-n_estimators100-max_depth5-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=5, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'RandomForestClassifier-n_estimators100-max_depth10-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=10, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'RandomForestClassifier-n_estimators100-max_depth50-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=50, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'RandomForestClassifier-n_estimators100-max_depth100-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=100, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'RandomForestClassifier-n_estimators1000-max_depthNone-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'RandomForestClassifier-n_estimators1000-max_depth1-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=1, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'RandomForestClassifier-n_estimators1000-max_depth5-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=5, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'RandomForestClassifier-n_estimators1000-max_depth10-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=10, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'RandomForestClassifier-n_estimators1000-max_depth50-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=50, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False), 'RandomForestClassifier-n_estimators1000-max_depth100-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=100, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)}
    name: donors_choose
    output_root_dir: /Users/satej/Documents/workspace/classwork/machine-learning/capp30254/hw5/code/output

Loading data
Running custom summary function

Running transformations for cleaning
    Applying transformation (1/4): convert-date_posted-to-datetime 
    date_posted -> date_posted
    Applying transformation (2/4): convert-datefullyfunded-to-datetime 
    datefullyfunded -> datefullyfunded
    Applying transformation (3/4): month_posted 
    ['date_posted'] -> month_posted
    Applying transformation (4/4): funded_in_60_days 
    ['date_posted', 'datefullyfunded'] -> funded_in_60_days


Running transformations for preprocessing
    Applying transformation (1/1): replace-missing-values-with-value(students_reached,0) 
    ['students_reached'] -> students_reached_clean


Running transformations for feature generation
    Applying transformation (1/12): categorize-school_city 
    ['school_city'] -> school_city_categorical
    Applying transformation (2/12): categorize-school_state 
    ['school_state'] -> school_state_categorical
    Applying transformation (3/12): categorize-primary_focus_subject 
    ['primary_focus_subject'] -> primary_focus_subject_categorical
    Applying transformation (4/12): categorize-primary_focus_area 
    ['primary_focus_area'] -> primary_focus_area_categorical
    Applying transformation (5/12): categorize-resource_type 
    ['resource_type'] -> resource_type_categorical
    Applying transformation (6/12): categorize-poverty_level 
    ['poverty_level'] -> poverty_level_categorical
    Applying transformation (7/12): categorize-grade_level 
    ['grade_level'] -> grade_level_categorical
    Applying transformation (8/12): binarize-school_charter 
    ['school_charter'] -> school_charter_binary
    Applying transformation (9/12): binarize-school_magnet 
    ['school_magnet'] -> school_magnet_binary
    Applying transformation (10/12): scale-by-max(students_reached_clean) 
    ['students_reached_clean'] -> students_reached_clean_scaled
    Applying transformation (11/12): scale-by-max(total_price_including_optional_support) 
    ['total_price_including_optional_support'] -> total_price_including_optional_support_scaled
    Applying transformation (12/12): binarize-eligible_double_your_impact_match 
    ['eligible_double_your_impact_match'] -> eligible_double_your_impact_match_binary

Training models.
Features: ['school_charter_binary', 'primary_focus_area_categorical', 'school_state_categorical', 'resource_type_categorical', 'eligible_double_your_impact_match_binary', 'school_city_categorical', 'grade_level_categorical', 'school_magnet_binary', 'students_reached_clean_scaled', 'total_price_including_optional_support_scaled', 'primary_focus_subject_categorical', 'poverty_level_categorical']
Fitting: funded_in_60_days
    Training model LinearSVC-C0.01-penaltyl2
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LinearSVC-C0.1-penaltyl2
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LinearSVC-C1-penaltyl2
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LinearSVC-C10-penaltyl2
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LinearSVC-C100-penaltyl2
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LogisticRegression-C0.01-penaltyl1-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LogisticRegression-C0.01-penaltyl2-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LogisticRegression-C0.1-penaltyl1-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LogisticRegression-C0.1-penaltyl2-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LogisticRegression-C1-penaltyl1-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LogisticRegression-C1-penaltyl2-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LogisticRegression-C10-penaltyl1-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LogisticRegression-C10-penaltyl2-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LogisticRegression-C100-penaltyl1-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model LogisticRegression-C100-penaltyl2-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model KNeighborsClassifier-n_neighbors10-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model KNeighborsClassifier-n_neighbors50-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model KNeighborsClassifier-n_neighbors100-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model DecisionTreeClassifier-max_depthNone
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model DecisionTreeClassifier-max_depth1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model DecisionTreeClassifier-max_depth5
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model DecisionTreeClassifier-max_depth10
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model DecisionTreeClassifier-max_depth50
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model DecisionTreeClassifier-max_depth100
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model GradientBoostingClassifier-learning_rate0.1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model GradientBoostingClassifier-learning_rate0.5
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model GradientBoostingClassifier-learning_rate2.0
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model BaggingClassifier-max_samples0.1-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model BaggingClassifier-max_samples0.5-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model BaggingClassifier-max_samples1.0-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model RandomForestClassifier-n_estimators10-max_depthNone-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model RandomForestClassifier-n_estimators10-max_depth1-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model RandomForestClassifier-n_estimators10-max_depth5-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model RandomForestClassifier-n_estimators10-max_depth10-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model RandomForestClassifier-n_estimators10-max_depth50-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model RandomForestClassifier-n_estimators10-max_depth100-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model RandomForestClassifier-n_estimators100-max_depthNone-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model RandomForestClassifier-n_estimators100-max_depth1-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model RandomForestClassifier-n_estimators100-max_depth5-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model RandomForestClassifier-n_estimators100-max_depth10-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model RandomForestClassifier-n_estimators100-max_depth50-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model RandomForestClassifier-n_estimators100-max_depth100-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model RandomForestClassifier-n_estimators1000-max_depthNone-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model RandomForestClassifier-n_estimators1000-max_depth1-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model RandomForestClassifier-n_estimators1000-max_depth5-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model RandomForestClassifier-n_estimators1000-max_depth10-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model RandomForestClassifier-n_estimators1000-max_depth50-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
    Training model RandomForestClassifier-n_estimators1000-max_depth100-n_jobs-1
        Training on training set "split 0" (1/3)
        Training on training set "split 1" (2/3)
        Training on training set "split 2" (3/3)
Testing models.
    Evaluating model LinearSVC-C0.01-penaltyl2
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LinearSVC-C0.1-penaltyl2
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LinearSVC-C1-penaltyl2
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LinearSVC-C10-penaltyl2
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LinearSVC-C100-penaltyl2
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LogisticRegression-C0.01-penaltyl1-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LogisticRegression-C0.01-penaltyl2-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LogisticRegression-C0.1-penaltyl1-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LogisticRegression-C0.1-penaltyl2-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LogisticRegression-C1-penaltyl1-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LogisticRegression-C1-penaltyl2-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LogisticRegression-C10-penaltyl1-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LogisticRegression-C10-penaltyl2-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LogisticRegression-C100-penaltyl1-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model LogisticRegression-C100-penaltyl2-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model KNeighborsClassifier-n_neighbors10-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model KNeighborsClassifier-n_neighbors50-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model KNeighborsClassifier-n_neighbors100-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model DecisionTreeClassifier-max_depthNone
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model DecisionTreeClassifier-max_depth1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model DecisionTreeClassifier-max_depth5
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model DecisionTreeClassifier-max_depth10
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model DecisionTreeClassifier-max_depth50
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model DecisionTreeClassifier-max_depth100
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model GradientBoostingClassifier-learning_rate0.1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model GradientBoostingClassifier-learning_rate0.5
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model GradientBoostingClassifier-learning_rate2.0
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model BaggingClassifier-max_samples0.1-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model BaggingClassifier-max_samples0.5-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model BaggingClassifier-max_samples1.0-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model RandomForestClassifier-n_estimators10-max_depthNone-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model RandomForestClassifier-n_estimators10-max_depth1-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model RandomForestClassifier-n_estimators10-max_depth5-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model RandomForestClassifier-n_estimators10-max_depth10-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model RandomForestClassifier-n_estimators10-max_depth50-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model RandomForestClassifier-n_estimators10-max_depth100-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model RandomForestClassifier-n_estimators100-max_depthNone-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model RandomForestClassifier-n_estimators100-max_depth1-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model RandomForestClassifier-n_estimators100-max_depth5-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model RandomForestClassifier-n_estimators100-max_depth10-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model RandomForestClassifier-n_estimators100-max_depth50-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model RandomForestClassifier-n_estimators100-max_depth100-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model RandomForestClassifier-n_estimators1000-max_depthNone-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model RandomForestClassifier-n_estimators1000-max_depth1-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model RandomForestClassifier-n_estimators1000-max_depth5-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model RandomForestClassifier-n_estimators1000-max_depth10-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model RandomForestClassifier-n_estimators1000-max_depth50-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
    Evaluating model RandomForestClassifier-n_estimators1000-max_depth100-n_jobs-1
        Evaluating on testing set "split 0" (1/3):
        Evaluating on testing set "split 1" (2/3):
        Evaluating on testing set "split 2" (3/3):
Copying artifacts to stable path
