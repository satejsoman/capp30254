\documentclass[11pt]{article}

% packages
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{extramarks}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
%\usepackage{amsfonts}
\usepackage{tikz}
\usepackage[plain]{algorithm}
\usepackage{algpseudocode}
\usepackage{lastpage}
\usepackage{units}
\usepackage[margin=0.75in]{geometry}
\usepackage{pgfplots}
\pgfplotsset{compat=1.16}
\usepackage{sectsty}
\usepackage{hyperref}
\usepackage{multicol}
\usepackage{mathtools}
\usepackage{tikz}
\usetikzlibrary{matrix}
\usepackage{listings}
\usepackage[plain]{algorithm}
\usepackage{algpseudocode}
\usepackage{mdframed}
\usepackage{booktabs}
\usepackage{multirow}

\definecolor{sblue}{HTML}{5292c0}
\definecolor{sgreen}{HTML}{93c47d}
\definecolor{sorange}{HTML}{e69138}
\definecolor{codeblue}{rgb}{0.29296875, 0.51953125, 0.68359375}
\definecolor{codegreen}{rgb}{0.47265625, 0.62890625, 0.40234375}
\definecolor{codegray}{rgb}{0.95703125, 0.95703125, 0.95703125}
\definecolor{codecrimson}{rgb}{0.87109375,0.3984375,0.3984375}

\lstset{frame=tb,
  backgroundcolor=\color{codegray},
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=left,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{codeblue},
  commentstyle=\color{codegreen},
  stringstyle=\color{codecrimson},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=4,
  frame=tlbr,framesep=4pt,framerule=0pt,
  literate={`}{\`}1,
}

% colors
\definecolor{sblue}{HTML}{5292c0}
\definecolor{sgreen}{HTML}{93c47d}
\definecolor{sorange}{HTML}{e69138}

% sectioning magic
\counterwithin*{equation}{section}
%\numberwithin{equation}{section}

% fonts
\usepackage{fontspec}
\newfontfamily\headerfontlt{ITC Franklin Gothic Std Book}
\newfontfamily\headerfont{ITC Franklin Gothic Std Demi}
\usepackage[urw-garamond]{mathdesign}
\usepackage{garamondx}
\usepackage[italic]{mathastext}

\newcommand{\printsection}[1]{\normalfont\headerfontlt{{{#1}}}}
\newcommand{\printsubsection}[1]{\normalfont\headerfontlt\textcolor{darkgray}{{#1}}}
\newcommand{\printsubsubsection}[1]{\normalfont\headerfontlt{{#1}}}
\allsectionsfont{\printsection}
\subsectionfont{\printsection}
\subsectionfont{\printsubsection}
\subsubsectionfont{\printsubsubsection}


\renewcommand{\headrulewidth}{0.1pt}
\renewcommand{\headrule}{\hbox to\headwidth{\color{gray}\leaders\hrule height \headrulewidth\hfill}}
\renewcommand{\footrulewidth}{0.0pt}

\newcommand{\op}[1]{\textrm{\small\printsubsection{\MakeUppercase{#1}}}\,}
\newcommand{\opns}[1]{\textrm{\small\printsubsection{\MakeUppercase{#1}}}}
\newcommand{\Partial}[1]{\partial\hspace{-0.2ex}{#1}}
\newcommand{\D}[1]{\mathrm{d}#1}
\newcommand{\E}[1]{\mathbb{E}{\left[\,#1\,\right]}}
\newcommand{\var}[1]{\mathrm{var}\left( #1 \right)}
\newcommand{\cov}[1]{\mathrm{cov}\left( #1 \right)}
\newcommand{\pr}[1]{\mathrm{Pr}\left( #1 \right)}
\newcommand{\given}{\,|\,}
\renewcommand{\det}{\mathrm{det\,}}
\renewcommand{\det}[1]{\op{det}\left(#1\right)}
\renewcommand{\ker}{\mathrm{Ker\,}}
\newcommand{\trace}[1]{\op{trace}\left(#1\right)}
\newcommand{\nul}[1]{\op{nul}\left(#1\right)}
\newcommand{\col}[1]{\op{col}\left(#1\right)}
\newcommand{\row}[1]{\op{row}\left(#1\right)}
\newcommand{\rank}[1]{\op{rank}\left(#1\right)}
\renewcommand{\dim}[1]{\op{dim}\left(#1\right)}
\newcommand{\im}{\op{Im\,}}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\complex}{\mathbb{C}}
\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand*{\matr}[1]{\mathbfit{#1}}
\newcommand*{\tran}{^{\mkern-1.5mu\mathsf{T}}}
\newcommand*{\conj}[1]{\overline{#1}}
\newcommand*{\hermconj}{^{\mathsf{H}}}
\newcommand*{\inv}{^{-1}}

%\setlength\parindent{0pt}
\linespread{1.1}
\pagecolor{gray!1}


% header/footer
\topmargin=-0.65in
\pagestyle{fancy}\fancyhf{} 
\lhead{\headerfontlt{\textcolor{darkgray}{Satej Soman \textcolor{gray}{$\big/$} CAPP30254, Spring 19 \textcolor{gray}{$\big/$}} Homework 3}}
\rhead{\headerfontlt{\textcolor{gray}{$\big[$} \thepage\ \textcolor{gray}{$\big/$} \pageref{LastPage} \textcolor{gray}{$\big]$}}}

\begin{document}
\begin{titlepage}
\raggedleft\huge\headerfontlt{
\textcolor{darkgray}{Satej Soman\\
CAPP30254: Machine Learning for Public Policy\\
Spring 2019}}

\vspace{240pt}
\Huge\headerfontlt{\textcolor{darkgray}{HW 3\\MACHINE LEARNING PIPELINE\\IMPROVEMENTS \& EVALUATION}}
\vfill
\normalfont \normalsize
\tableofcontents

\end{titlepage}
\section*{Notes}
\begin{itemize}
\item Representative code snippets are interspersed with analysis and explanations below; all code is available on GitHub: \url{https://github.com/satejsoman/capp30254/tree/master/hw3}.
\item The pipeline library lives in the \texttt{code/pipeline} directory, while the sample application which imports the library is \texttt{code/donors\_choose.py}.
\item The generated table of hyperparameters is uploaded as a separate CSV; it also is available on GitHub as \texttt{code/evaluations.csv}.
\end{itemize}

\section{Coding: Pipeline Improvements}
\subsection{Improvements}
The following improvements have been made to the \texttt{pipeline} library:
\begin{itemize}
\item The library now includes a stage to generate train/test data splits. Due to the object-oriented design, the current implementation can easily be overriden by subclassing or monkey-patching in specific applications.
\item Additional metrics, besides accuracy, have been added to the model evaluation. Specifically, precision, recall, and ROC-AUC have been added to the model evaluation stage.
\end{itemize}

\subsection{Additional Models}
In the original pipeline design, the model was not hard-coded, so pipeline runs can be parametrized by the model implementation: 

\begin{lstlisting}[language=Python,numbers=none]
donors_choose_preprocessors = [
    ...
]
donors_choose_feature_generators = [
    ...
]

models_to_run = { 
    ...
}

def model_parametrized_pipeline(description, model):
    return Pipeline(input_path, "funded_in_60_days",
        summarize=False,
        data_preprocessors=donors_choose_preprocessors,
        feature_generators=donors_choose_feature_generators,
        name="donors-choose-" + description,
        model=model
        output_root_dir="output")

for (description, model) in models_to_run.items():
    model_parametrized_pipeline(description, model).run()
\end{lstlisting}

The above code is purely representative; in implementation, the data generation and feature preprocessing are done in a separate pipeline. The results of this pipeline are serialized and fed in as the inputs to a pipeline that solely trains and tests models. In this way, computation to process data and create feature vectors is not repeated for every trial run.


\section{Analysis: Application to DonorsChoose Project Funding Viability}

\subsection{Background}
DonorsChoose.org is a platform for soliciting donations for K-12 schools in need. Teachers post a project proposal highlighting a shortfall of resources at their institution as well as information about what areas of study will benefit from the project meeting its funding requirements. Additional data available on DonorsChoose.org describe the socioeconomic status and geography of the school, as well as characteristics of the teacher. 

Responding to shortfalls in educational resources is a time-sensitive matter; donors and teachers should therefore understand the factors that determine whether a project will succeed within a reasonable amount of time (in this analysis, 60 days). Correctly predicting which projects are viable allows for effective use of time and resources for both the donors and the schools. 

\subsection{Data Exploration}
Preliminary inspection of the data identifies columns that should be excluded from further analysis. Project- and school-specific identifiers such as \texttt{projectid},  \texttt{school\_ncesid}, and \texttt{schoolid} are not useful for predicting funding success. Additionally, we choose to \textit{exclude} the teacher's preferred prefix (\texttt{teacher\_prefix}) because it proxies stated gender, a protected class under Title VII. 

Table \ref{summary} shows summary statistics for other numerical inputs. While latitude and longitude are potentially good predictors, geographic variation can be captured by categorical variables such as \texttt{school\_city}, \texttt{school\_state}, and \texttt{school\_district}. 

Further, we can see that two other predictors, the number of students reached and the total price, need to be scaled since many of the other predictors are binary. Without scaling, the use of these predictors will degrade SVM performance, and distort results in $k$-nearest neighbors analysis.

Finally, we also see that 71\% of projects are funded within 60 days. A good baseline classifier would one that randomly predicts success with a probability of 71\%.
\begin{table}[H]
\centering \small \renewcommand{\arraystretch}{1.1}
\input{summary.tex}
\caption{Table of summary statistics for additional numerical vectors.}\label{summary}
\end{table}

Additionally, other input vectors have missing values. Depending on the number of missing values and the domain context, we can fill in missing values, or exclude overly sparse vectors from our models. Table \ref{missing} shows that variables such as the schools metropolitan area and the projects secondary focus are likely too sparse to support filling with placeholder values, whereas appropriate missing values for resource type, grade level, and students reached can be found by examining the distributions for those variables. As an example, Figure \ref{sr_dist} shows the distribution of \texttt{students\_reached} - downcoding missing values to 0 is an appropriate approximation for the number of students reached and will not materially change the distribution.

\begin{minipage}[c]{0.3\pagewidth}
\vspace{0pt}
\begin{table}[H]
\centering \small \renewcommand{\arraystretch}{1.1}
\input{missing.tex}
\caption{Vectors with missing values.}\label{missing}
\end{table}
\end{minipage} \hfill \begin{minipage}[c]{0.45\pagewidth}
\vspace{0pt}
\begin{figure}[H]
\centering
\input{students_reached.tex}
\caption{Distribution of number of students reached.} \label{sr_dist}
\end{figure}
\end{minipage}

\subsection{Feature Selection}
As discussed above, we exclude teacher characteristics but focus on project-level, school-specific, and temporal variables. Table \ref{features} lists the chosen features and provides a summary of each. 
\begin{table}[H]
\centering \small \renewcommand{\arraystretch}{1.1}
\input{features.tex}
\caption{Features passed to machine learning models.}\label{features}
\end{table}

\subsection{Classifier Models}
A number of classifiers are used to try and predict which projects on DonorsChoose will be funded. The implementations available through scikit-learn offer a number of parameters influencing the performance of the classifier. 

\begin{table}[H]
\centering \small \renewcommand{\arraystretch}{1.1}
\input{classifiers.tex}
\caption{Classifiers and parameters tested.}\label{classifiers}
\end{table}

\subsection{Methodology}
All available data were split into three training/validation data sets. The three validation sets were the three periods of six months each preceding 31 December, 2013. Each training set was comprised of all data up until the beginning of each validation set.

The values of the parameters in Table \ref{classifiers} were varied and evaluation metrics were calculated for each training set. The metrics used in this analysis were: precision, recall, F1, area under receiver-operator characteristic curve, and mean accuracy.

\section{Report: Classifier Performance}
\subsection{Metric Choice}
As stated in the initial analysis, we should focus on projects likely to succeed - this indicates \textbf{recall} is the metric that is most important in choosing a classifier.

\subsection{Analysis of Hyperparameter Tuning}
Sorting the results of hyperparameter tuning of all models indicates that a simple decision tree is the best classifier. However, the decision trees, regardless of criterion, only perform well on the first two training/test periods. Since decision trees are the base classifier of the random forest approach in this implementation, all random forest approaches also exhibit this problem, despite the use of boosting and bagging techniques.

Logistic regression, conversely, performs fairly well across all test/train sets. On this data set, neither varying the cost parameter nor switching from LASSO to ridge regularization vastly impacted performance when measured by recall. (Precision for all logistic regression classifiers fell for test/train set \#2)

\subsection{Temporal Trends}
Interestingly, many classifiers suffer from the problem of doing well on the first two training/testing sets but suffering in performance when evaluated on the third set. Further analysis is required to determine if general equilibrium effects warrant handling projects posted in late 2013 differently. For example, an increase in popularity of the DonorsChoose platform due to initial funding success may cause a flood of less-viable projects to be posted in the second half of 2013.

\end{document} 
